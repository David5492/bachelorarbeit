{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\test\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:23:25.682829\n"
     ]
    }
   ],
   "source": [
    "# intendet steps:\n",
    "    # 1. Impute Missing Values\n",
    "    # 2. Transform vía scipy.stats.boxcox(data, lmbda=) (spare ich mir)\n",
    "    # 3. Outliers vía scipy.stats.mstats.winsorize(limits=[0.05,0.05])\n",
    "    # 4. Scaling vía StandardScaler() und MinMaxScaler()\n",
    "    # 5. NLP\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy import stats\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats.mstats import winsorize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "# Load data\n",
    "df= pd.read_csv(\"C:/Users/test/Documents/GitHub/bachelorarbeit/_climate_change_mitigation/data/interim/berlin_clean.csv\")\n",
    "\n",
    "# define subset lists\n",
    "text = ['description_misc','description_clear','equipment_clear','description_location', 'title']\n",
    "\n",
    "categorials = ['type','pets','condition','quality_of_appliances',\n",
    "                'heating_type','energy_certificate_type','ground_plan',\n",
    "                'energy_sources','parking_kind','hot_water_included',\n",
    "                'city_code','energy', 'energy_certificate']\n",
    "\n",
    "numericals = ['energy_consumption','rent','utilities_cost','heating_cost','cost_total',\n",
    "                'area','rooms','bedrooms','bathrooms','year_built',\n",
    "                'last_renovated','latitude','longitude','floor_act',\n",
    "                'floor_max','parking_spaces']\n",
    "\n",
    "\n",
    "# create sub dfs:\n",
    "df_categorials_dummies = pd.get_dummies(df[categorials])\n",
    "df_num = df[numericals]\n",
    "df_text = df[text] #.fillna('XXX') # nur testweise\n",
    "\n",
    "\n",
    "# Impute missing num \n",
    "\n",
    "median_impute = ['utilities_cost','heating_cost','latitude','longitude','floor_act',\n",
    "                'floor_max','parking_spaces']\n",
    "most_frequent_impute = ['bedrooms','bathrooms','year_built','last_renovated',]\n",
    "\n",
    "for col in median_impute:\n",
    "    imp_median = SimpleImputer(strategy='median')\n",
    "    df_num[col] = imp_median.fit_transform(df_num[[col]])\n",
    "\n",
    "for col in most_frequent_impute:\n",
    "    imp_mf = SimpleImputer(strategy='most_frequent')\n",
    "    df_num[col] = imp_mf.fit_transform(df_num[[col]])\n",
    "\n",
    "\n",
    "# Impute missing text \n",
    "\n",
    "def text_imputer(text):\n",
    "    \"\"\"\n",
    "    Rechnet mit einem str.\n",
    "    Prüft ob ein Wert nan ist und ersetzt ihn gegebenfalls mit Kauderwelsch.\n",
    "    Sinn: NLP funktioniert sonst nicht und bei einem anderen Impute entsteht\n",
    "    ein Bias. \n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=random.randint(50,100)))\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "for col in df_text.columns: \n",
    "    df_text[col] = df_text[col].apply(text_imputer)\n",
    "\n",
    "\n",
    "# Kill outliers by setting upper and lower limits\n",
    "\n",
    "for col in df_num.columns: \n",
    "    masked_array = winsorize(df_num[col], limits =[0.005,0.005])\n",
    "    df_num[col] = pd.DataFrame(masked_array, columns = [col])\n",
    "\n",
    "# Save data for EDA:\n",
    "df_EDA = pd.concat([df_num, df[categorials], df_text], axis=1)\n",
    "df_EDA = df_EDA.reset_index(drop=True)\n",
    "df_EDA.to_csv(\"C:/Users/test/Documents/GitHub/bachelorarbeit/_climate_change_mitigation/data/processed/berlin_preprocessed_EDA.csv\", index = False)\n",
    "\n",
    "\n",
    "# NLP:\n",
    "\n",
    "def text_process(annonce):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Produces word stems\n",
    "    4. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in annonce if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # remove any german stopwords\n",
    "    nostop = [word for word in nopunc.split() if word.lower() not in stopwords.words('german')]\n",
    "\n",
    "    # Reduce words to their stem\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(word) for word in nostop]\n",
    "\n",
    "# All cells of text in one col:\n",
    "df_text['all_cols'] = df_text.iloc[:,1:].apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "# strings to token integer counts\n",
    "bow_transformer = CountVectorizer(analyzer=text_process, max_df=0.99, min_df=0.01).fit(df_text['all_cols']) \n",
    "\n",
    "#transform all annoces:\n",
    "annoces_bow = bow_transformer.transform(df_text['all_cols'])\n",
    "\n",
    "# tfidf-transformer:\n",
    "tfidf_transformer = TfidfTransformer().fit(annoces_bow)\n",
    "\n",
    "# transform the bow:\n",
    "annonces_tfidf = tfidf_transformer.transform(annoces_bow)\n",
    "\n",
    "# transform sparse matrix to pd.DataFrame\n",
    "df_former_sparse = pd.DataFrame.sparse.from_spmatrix(annonces_tfidf)\n",
    "\n",
    "stop = datetime.now()\n",
    "print(str(stop - start)) #just4fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Build RFRegressor for sorting the Importances of the words. \n",
    "y = df_num['energy_consumption']\n",
    "X = df_former_sparse\n",
    "     \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)\n",
    "\n",
    "RFReg = RandomForestRegressor(random_state=42)\n",
    "RFReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:22:35.860130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_importance_sorted_idx = np.argsort(RFReg.feature_importances_)\n",
    "df_sorted_features = X[tree_importance_sorted_idx[:251]]\n",
    "\n",
    "# concat all sub-dfs\n",
    "df_all = pd.concat([df_num, df_categorials_dummies, df_sorted_features], axis=1)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "# save data for modelling:\n",
    "df_all.to_csv(\"C:/Users/test/Documents/GitHub/bachelorarbeit/_climate_change_mitigation/data/processed/berlin_preprocessed.csv\", index = False)\n",
    "\n",
    "\n",
    "stop = datetime.now()\n",
    "print(str(stop - start)) #just4fun\n",
    "\n",
    "# Time: 00:23:20. Haha, das war VOR dem Tree, um die Wortwichtigkeit zu erkennen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16911, 334)\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3aaf935e6aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.20844673973087"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
